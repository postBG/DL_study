{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Save and Restore TensorFlow Models\n",
    "Training a model can take hours. But once you close your TensorFlow session, you lose all the trained weights and biases. If you were to reuse the model in the future, you would have to train it all over again!\n",
    "\n",
    "Fortunately, TensorFlow gives you the ability to save your progress using a class called **tf.train.Saver**. This class provides the functionality to save any tf.Variable to your file system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Variables\n",
    "Let's start with a simple example of saving weights and bias Tensors. For the first example you'll just save two variables. Later examples will save all the weights in a practical model.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "```\n",
    "\n",
    "> Weights:\n",
    "\n",
    "> [[-0.97990924 1.03016174 0.74119264]\n",
    "\n",
    "> [-0.82581609 -0.07361362 -0.86653847]]\n",
    "\n",
    "> Bias:\n",
    "\n",
    "> [ 1.62978125 -0.37812829 0.64723819]\n",
    "\n",
    "The Tensors **weights** and **bias** are set to random values using the **tf.truncated_normal()** function. The values are then saved to the **save_file** location, \"model.ckpt\", using the **tf.train.Saver.save()** function. (The \".ckpt\" extension stands for \"checkpoint\".)\n",
    "\n",
    "If you're using TensorFlow 0.11.0RC1 or newer, a file called \"model.ckpt.meta\" will also be created. This file contains the TensorFlow graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Variables\n",
    "Now that the Tensor Variables are saved, let's load them back into a new model.\n",
    "\n",
    "```python\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "```\n",
    "\n",
    ">Weights:\n",
    "\n",
    ">[[-0.97990924 1.03016174 0.74119264]\n",
    "\n",
    "> [-0.82581609 -0.07361362 -0.86653847]]\n",
    "\n",
    "> Bias:\n",
    "\n",
    "> [ 1.62978125 -0.37812829 0.64723819]\n",
    "\n",
    "You'll notice you still need to create the **weights** and **bias** Tensors in Python. The **tf.train.Saver.restore()** function loads the saved data into **weights** and **bias**.\n",
    "\n",
    "Since **tf.train.Saver.restore()** sets all the TensorFlow Variables, you don't need to call **tf.global_variables_initializer()**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a Trained Model\n",
    "Let's see how to train a model and save its weights.\n",
    "\n",
    "First start with a model:\n",
    "\n",
    "```python\n",
    "# Remove previous Tensors and Operations\n",
    "tf.reset_default_graph()\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "learning_rate = 0.001\n",
    "n_input = 784  # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "\n",
    "# Import MNIST data\n",
    "mnist = input_data.read_data_sets('.', one_hot=True)\n",
    "\n",
    "# Features and Labels\n",
    "features = tf.placeholder(tf.float32, [None, n_input])\n",
    "labels = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "# Weights & bias\n",
    "weights = tf.Variable(tf.random_normal([n_input, n_classes]))\n",
    "bias = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "# Logits - xW + b\n",
    "logits = tf.add(tf.matmul(features, weights), bias)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Calculate accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "```\n",
    "\n",
    "Let's train that model, then save the weights:\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "save_file = './train_model.ckpt'\n",
    "batch_size = 128\n",
    "n_epochs = 100\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(n_epochs):\n",
    "        total_batch = math.ceil(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_features, batch_labels = mnist.train.next_batch(batch_size)\n",
    "            sess.run(\n",
    "                optimizer,\n",
    "                feed_dict={features: batch_features, labels: batch_labels})\n",
    "\n",
    "        # Print status for every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            valid_accuracy = sess.run(\n",
    "                accuracy,\n",
    "                feed_dict={\n",
    "                    features: mnist.validation.images,\n",
    "                    labels: mnist.validation.labels})\n",
    "            print('Epoch {:<3} - Validation Accuracy: {}'.format(\n",
    "                epoch,\n",
    "                valid_accuracy))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)\n",
    "    print('Trained Model Saved.')\n",
    "```\n",
    "\n",
    ">Epoch 0 - Validation Accuracy: 0.06859999895095825\n",
    "\n",
    ">Epoch 10 - Validation Accuracy: 0.20239999890327454\n",
    "\n",
    ">Epoch 20 - Validation Accuracy: 0.36980000138282776\n",
    "\n",
    ">Epoch 30 - Validation Accuracy: 0.48820000886917114\n",
    "\n",
    ">Epoch 40 - Validation Accuracy: 0.5601999759674072\n",
    "\n",
    ">Epoch 50 - Validation Accuracy: 0.6097999811172485\n",
    "\n",
    ">Epoch 60 - Validation Accuracy: 0.6425999999046326\n",
    "\n",
    ">Epoch 70 - Validation Accuracy: 0.6733999848365784\n",
    "\n",
    ">Epoch 80 - Validation Accuracy: 0.6916000247001648\n",
    "\n",
    ">Epoch 90 - Validation Accuracy: 0.7113999724388123\n",
    "\n",
    ">Trained Model Saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Trained Model\n",
    "Let's load the weights and bias from memory, then check the test accuracy.\n",
    "\n",
    "```pyhton\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    test_accuracy = sess.run(\n",
    "        accuracy,\n",
    "        feed_dict={features: mnist.test.images, labels: mnist.test.labels})\n",
    "\n",
    "print('Test Accuracy: {}'.format(test_accuracy))\n",
    "```\n",
    "\n",
    ">Test Accuracy: 0.7229999899864197\n",
    "\n",
    "That's it! You now know how to save and load a trained model in TensorFlow. Let's look at loading weights and biases into modified models in the next section."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
